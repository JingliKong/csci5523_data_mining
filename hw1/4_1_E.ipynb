{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 10:56:06 WARN Utils: Your hostname, LAPTOP-0S5927HR resolves to a loopback address: 127.0.1.1; using 192.168.250.233 instead (on interface eth0)\n",
      "23/02/03 10:56:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 10:56:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark \n",
    "import argparse \n",
    "import json \n",
    "\n",
    "# 4.1.1 E: Top n frequent words in the review text\n",
    "\n",
    "sc_conf = pyspark.SparkConf()\n",
    "sc_conf.setAppName('task1')  \n",
    "sc_conf.setMaster('local[*]') \n",
    "sc_conf.set('spark.driver.memory', '8g')\n",
    "sc_conf.set('spark.executor.memory', '4g')\n",
    "# sc = pyspark.SparkContext(conf=sc_conf)\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "sc.setLogLevel(\"OFF\")\n",
    "\n",
    "# read in the lines and create the rdd \n",
    "lines = sc.textFile(\"./data/review.json\")\n",
    "\n",
    "# loading the json into a python object \n",
    "rdd = lines.map(lambda line: json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = [\"(\", \"[\", \",\", \".\", \"!\", \"?\", \":\", \";\", \"]\", \")\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', '']]\n"
     ]
    }
   ],
   "source": [
    "stopwords = []\n",
    "with open('./data/stopwords') as f: \n",
    "    stopwords.append(f.read().split('\\n'))\n",
    "print(stopwords[0:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = rdd.map(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_words = text.map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"walked in around 4 on a friday afternoon, we sat at a table just off the bar and walked out after 5 min or so. don't even think they realized we walked in. however everyone at the bar noticed we walked in!!! service was non existent at best. not a good way for a new business to start out. oh well, the location they are at has been about 5 different things over the past several years, so they will just be added to the list. smdh!!!\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitting_words.take(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to filter by character \n",
    "counts = splitting_words.map(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['walked',\n",
       "  'in',\n",
       "  'around',\n",
       "  '4',\n",
       "  'on',\n",
       "  'a',\n",
       "  'friday',\n",
       "  'afternoon,',\n",
       "  'we',\n",
       "  'sat',\n",
       "  'at',\n",
       "  'a',\n",
       "  'table',\n",
       "  'just',\n",
       "  'off',\n",
       "  'the',\n",
       "  'bar',\n",
       "  'and',\n",
       "  'walked',\n",
       "  'out',\n",
       "  'after',\n",
       "  '5',\n",
       "  'min',\n",
       "  'or',\n",
       "  'so.',\n",
       "  \"don't\",\n",
       "  'even',\n",
       "  'think',\n",
       "  'they',\n",
       "  'realized',\n",
       "  'we',\n",
       "  'walked',\n",
       "  'in.',\n",
       "  'however',\n",
       "  'everyone',\n",
       "  'at',\n",
       "  'the',\n",
       "  'bar',\n",
       "  'noticed',\n",
       "  'we',\n",
       "  'walked',\n",
       "  'in!!!',\n",
       "  'service',\n",
       "  'was',\n",
       "  'non',\n",
       "  'existent',\n",
       "  'at',\n",
       "  'best.',\n",
       "  'not',\n",
       "  'a',\n",
       "  'good',\n",
       "  'way',\n",
       "  'for',\n",
       "  'a',\n",
       "  'new',\n",
       "  'business',\n",
       "  'to',\n",
       "  'start',\n",
       "  'out.',\n",
       "  'oh',\n",
       "  'well,',\n",
       "  'the',\n",
       "  'location',\n",
       "  'they',\n",
       "  'are',\n",
       "  'at',\n",
       "  'has',\n",
       "  'been',\n",
       "  'about',\n",
       "  '5',\n",
       "  'different',\n",
       "  'things',\n",
       "  'over',\n",
       "  'the',\n",
       "  'past',\n",
       "  'several',\n",
       "  'years,',\n",
       "  'so',\n",
       "  'they',\n",
       "  'will',\n",
       "  'just',\n",
       "  'be',\n",
       "  'added',\n",
       "  'to',\n",
       "  'the',\n",
       "  'list.',\n",
       "  'smdh!!!']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = splitting_words.flatMap(lambda line: line.split(' ')) \\\n",
    "    .filter(lambda x: x not in stopwords) \\\n",
    "    .map(lambda word: (word, 1)).reduceByKey(lambda a, b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = splitting_words.flatMap(lambda line: line.split(' ')) \\\n",
    "    .filter(lambda x: x not in stopwords) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['walked', 'in', 'around']\n"
     ]
    }
   ],
   "source": [
    "print(counts.take(3))\n",
    "# counts = counts.filter(lambda x: x not in stopwords) \n",
    "# print(counts.collect()[0:3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = counts.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a+b)\n",
    "# print(counts.collect()[0:3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('even', 215856), ('they', 994327), ('noticed', 18323)]\n"
     ]
    }
   ],
   "source": [
    "final = counts.sortBy(lambda x: x[1], False)\n",
    "print(counts.collect()[0:3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(final.collect()[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49c7475afa802cdf659320c820863a127978f36b368c817ac9cb102b34b4cef7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
